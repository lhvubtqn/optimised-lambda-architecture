{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a2b7690",
   "metadata": {},
   "source": [
    "# Init PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd68b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark import  SparkContext, SparkConf\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "# Spark session & context\n",
    "conf = SparkConf()\n",
    "conf.setMaster(\"local[4]\").setAppName(\"stream-job\")\n",
    "conf.set(\"spark.executor.memory\", \"4g\")\n",
    "conf.set(\"spark.executor.cores\", \"1\")\n",
    "conf.set(\"spark.cores.max\", \"4\")\n",
    "conf.set(\"spark.driver.memory\",'4g')\n",
    "conf.set(\"spark.driver.extraClassPath\", \"/usr/local/spark/third-party-jars/*\")\n",
    "conf.set(\"spark.executor.extraClassPath\", \"/usr/local/spark/third-party-jars/*\")\n",
    "conf.set(\"spark.sql.caseSensitive\", \"true\")\n",
    "conf.set(\"spark.ui.port\", \"4040\")\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "sqlContext = SQLContext(sc)\n",
    "ssc = StreamingContext(sc, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f5fa63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.output_area pre {\n",
       "    white-space: pre;\n",
       "}\n",
       ".container { \n",
       "    width:95% !important; \n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "div.output_area pre {\n",
    "    white-space: pre;\n",
    "}\n",
    ".container { \n",
    "    width:95% !important; \n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c964e372",
   "metadata": {},
   "source": [
    "# Define static variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bf0be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_BIN_SECONDS = 600 # seconds\n",
    "DAY_TYPE_WEEKDAY = 0\n",
    "DAY_TYPE_WEEKEND = 0\n",
    "DATA_ACTUAL_TIMEZONE = \"America/Los_Angeles\"\n",
    "\n",
    "STATIC_DATA_DIR = \"hdfs://namenode:8020/ola/static_data/\"\n",
    "HISTORICAL_DATA_DIR = \"hdfs://namenode:8020/ola/historical_data/\"\n",
    "AGGREGATED_DATA_DIR = \"hdfs://namenode:8020/ola/aggregated_data/\"\n",
    "\n",
    "LOCAL_STATIC_DATA_DIR = \"/home/data/static_data/\"\n",
    "LOCAL_HISTORICAL_DATA_DIR = \"/home/data/historical_data/\"\n",
    "LOCAL_AGGREGATED_DATA_DIR = \"/home/data/aggregated_data/\"\n",
    "\n",
    "STATIC_DATA_DIR = LOCAL_STATIC_DATA_DIR\n",
    "HISTORICAL_DATA_DIR = LOCAL_HISTORICAL_DATA_DIR\n",
    "AGGREGATED_DATA_DIR = LOCAL_AGGREGATED_DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d862f1",
   "metadata": {},
   "source": [
    "# Define utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06de0b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cd6794",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe7d4ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "\n",
    "# check if segment is not an empty segment (two vertex is the same)\n",
    "def fis_not_the_same(from_latlon, to_latlon):\n",
    "    return (from_latlon[0] != to_latlon[0]) | (from_latlon[1] != to_latlon[1])\n",
    "\n",
    "def ffile_path_to_ts(file_path):\n",
    "    return int(file_path[-18:-4])\n",
    "\n",
    "def fget_time_bin(epoch_seconds):\n",
    "    dt = datetime.fromtimestamp(epoch_seconds)\n",
    "    dt = dt.astimezone(timezone(DATA_ACTUAL_TIMEZONE))\n",
    "    return math.floor((dt.hour * 3600 + dt.minute * 60 + dt.second) / TIME_BIN_SECONDS)\n",
    "\n",
    "def fget_day_type(epoch_seconds):\n",
    "    dt = datetime.fromtimestamp(epoch_seconds)\n",
    "    wd = dt.astimezone(timezone(DATA_ACTUAL_TIMEZONE)).weekday()\n",
    "    return DAY_TYPE_WEEKDAY if wd < 5 else DAY_TYPE_WEEKEND\n",
    "\n",
    "def fhaversine_meter(lat1, lon1, lat2, lon2):\n",
    "    # distance between latitudes and longitudes\n",
    "    dLat = (lat2 - lat1) * math.pi / 180.0\n",
    "    dLon = (lon2 - lon1) * math.pi / 180.0\n",
    "\n",
    "    # convert to radians\n",
    "    lat1 = (lat1) * math.pi / 180.0\n",
    "    lat2 = (lat2) * math.pi / 180.0\n",
    " \n",
    "    # apply formulae\n",
    "    a = (math.pow(math.sin(dLat / 2), 2) +\n",
    "         math.pow(math.sin(dLon / 2), 2) *\n",
    "             math.cos(lat1) * math.cos(lat2));\n",
    "    rad = 6371\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    return rad * c * 1000\n",
    "\n",
    "def ffind_distance(lat1, lon1, flat1, flon1, slat1, slon1, cl1, lat2, lon2, flat2, flon2, slat2, slon2, cl2):\n",
    "    if cl1 == cl2:\n",
    "        return fhaversine_meter(lat1, lon1, lat2, lon2)\n",
    "        \n",
    "    if cl1 > cl2:\n",
    "        return ffind_distance(lat2, lon2, flat2, flon2, slat2, slon2, cl2, lat1, lon1, flat1, flon1, slat1, slon1, cl1)\n",
    "\n",
    "    return fhaversine_meter(lat1, lon1, slat1, slon1) + cl2 - cl1 - fhaversine_meter(flat2, flon2, slat2, slon2) + fhaversine_meter(flat2, flon2, lat2, lon2)\n",
    "\n",
    "def readPostgreSQL(user, password, database, query):\n",
    "    ip = \"10.60.71.3\"\n",
    "    port = \"5432\"\n",
    "    url = \"jdbc:postgresql://\" + ip + \":\" + port + \"/\" + database \n",
    "    driver = \"org.postgresql.Driver\"\n",
    "    \n",
    "    return sqlContext.read\\\n",
    "        .format(\"jdbc\")\\\n",
    "        .option(\"url\", url)\\\n",
    "        .option(\"driver\", driver)\\\n",
    "        .option(\"url\", url)\\\n",
    "        .option(\"user\", user)\\\n",
    "        .option(\"password\", password)\\\n",
    "        .option(\"dbtable\", \"({}) as tmp\".format(query))\\\n",
    "        .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2adb961b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n"
     ]
    }
   ],
   "source": [
    "print(fget_time_bin(1620795062))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a8791d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffind_distance: 3913.794621512769 m\n"
     ]
    }
   ],
   "source": [
    "print(\"ffind_distance:\", ffind_distance(33.82962, -118.290314, 33.8292539188, -118.2902737058, 33.8296908268, -118.2902719251, 23232.5956910088, 33.794449, -118.290871, 33.7932864432, -118.2908173976, 33.7945806653, -118.2908159585, 19326.593863383834), \"m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a296a056",
   "metadata": {},
   "source": [
    "## Udf functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2aaff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#udf\n",
    "is_not_the_same = udf(lambda a, b: ffis_not_the_same(a, b), BooleanType())\n",
    "\n",
    "file_path_to_ts = udf(lambda a: ffile_path_to_ts(a), LongType())\n",
    "\n",
    "get_time_bin = udf(lambda a: fget_time_bin(a), IntegerType())\n",
    "\n",
    "get_day_type = udf(lambda a: fget_day_type(a), IntegerType())\n",
    "\n",
    "haversine_meter = udf(lambda a, b, c, d: fhaversine_meter(a, b, c, d), DoubleType())\n",
    "\n",
    "find_distance = udf(lambda a, b, c, d, e, f, g, h, p, q, r, s, t, u: ffind_distance(a, b, c, d, e, f, g, h, p, q, r, s, t, u), DoubleType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a522d1",
   "metadata": {},
   "source": [
    "# Load static data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5435de6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- route_id: string (nullable = true)\n",
      " |-- segment_cum_len: double (nullable = true)\n",
      " |-- segment_first_lat: double (nullable = true)\n",
      " |-- segment_first_lon: double (nullable = true)\n",
      " |-- segment_id: long (nullable = true)\n",
      " |-- segment_len_meter: double (nullable = true)\n",
      " |-- segment_second_lat: double (nullable = true)\n",
      " |-- segment_second_lon: double (nullable = true)\n",
      " |-- segment_sequence: long (nullable = true)\n",
      "\n",
      "+--------+------------------+-----------------+-----------------+----------+------------------+------------------+------------------+----------------+\n",
      "|route_id|   segment_cum_len|segment_first_lat|segment_first_lon|segment_id| segment_len_meter|segment_second_lat|segment_second_lon|segment_sequence|\n",
      "+--------+------------------+-----------------+-----------------+----------+------------------+------------------+------------------+----------------+\n",
      "|     125| 96.84797621031923|    33.9058578172|  -118.3960444204|         1| 96.84797621031923|     33.9067250829|   -118.3959476739|           10001|\n",
      "|     125|221.21825085184605|    33.9067250829|  -118.3959476739|         1|124.37027464152683|      33.907843507|    -118.395933184|           10002|\n",
      "|     125| 261.6967587613555|     33.907843507|   -118.395933184|         1| 40.47850790950947|     33.9078312067|   -118.3954948079|           10003|\n",
      "|     125| 289.3745612113418|    33.9078312067|  -118.3954948079|         1| 27.67780244998628|     33.9078294424|   -118.3951948978|           10004|\n",
      "|     125|327.10693172036974|    33.9078294424|  -118.3951948978|         1|37.732370509027916|     33.9078417726|   -118.3947862985|           10005|\n",
      "|     125| 340.8474310003585|    33.9078417726|  -118.3947862985|         1| 13.74049927998875|     33.9078532494|   -118.3946380495|           10006|\n",
      "|     125| 353.2559902120121|    33.9078532494|  -118.3946380495|         1|12.408559211653577|     33.9078756633|     -118.39450633|           10007|\n",
      "|     125| 375.6977006808677|    33.9078756633|    -118.39450633|         1| 22.44171046885558|      33.907931385|   -118.3942726027|           10008|\n",
      "|     125| 400.0596061124178|     33.907931385|  -118.3942726027|         1|24.361905431550085|     33.9080091319|   -118.3940257962|           10009|\n",
      "|     125|  588.243935307321|    33.9080091319|  -118.3940257962|         1|188.18432919490317|     33.9084799052|   -118.3920670982|           10010|\n",
      "+--------+------------------+-----------------+-----------------+----------+------------------+------------------+------------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60198"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes_segments = spark\\\n",
    "    .read\\\n",
    "    .json(STATIC_DATA_DIR + \"route_segments.json\")\\\n",
    "\n",
    "routes_segments.cache()\n",
    "routes_segments.printSchema()\n",
    "routes_segments.show(10)\n",
    "routes_segments.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0db4f45",
   "metadata": {},
   "source": [
    "# Load aggregated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_velocities = spark\\\n",
    "    .read\\\n",
    "    .json(AGGREGATED_DATA_DIR + \"avg_velocities.json\")\\\n",
    "\n",
    "avg_velocities.cache()\n",
    "avg_velocities.printSchema()\n",
    "avg_velocities.show(10)\n",
    "avg_velocities.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4e1f16",
   "metadata": {},
   "source": [
    "# Consume data from Kafka & process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cc2931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- req_time: long (nullable = true)\n",
      " |-- heading: double (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- predictable: boolean (nullable = true)\n",
      " |-- route_id: string (nullable = true)\n",
      " |-- run_id: string (nullable = true)\n",
      " |-- seconds_since_report: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"route_id\", StringType(), True),\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"run_id\", StringType(), True),\n",
    "    StructField(\"predictable\", BooleanType(), True),\n",
    "    StructField(\"seconds_since_report\", LongType(), True),\n",
    "    StructField(\"heading\", DoubleType(), True),\n",
    "    StructField(\"latitude\", DoubleType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# Subscribe to 1 topic defaults to the earliest and latest offsets\n",
    "bus_positions = spark \\\n",
    "    .read \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "    .option(\"subscribe\", \"buses-location\") \\\n",
    "    .load()\\\n",
    "    .withColumn('key', df.key.cast(StringType()))\\\n",
    "    .withColumn('value', df.value.cast(StringType()))\\\n",
    "    .select(functions.from_json(\"value\", schema).alias(\"bus_location\"))\\\n",
    "    .select(\"bus_location.*\")\n",
    "\n",
    "# calculate timestamp of record as: req_time - seconds_since_report, then convert it to timezone('America/Los_Angeles')\n",
    "bus_positions = bus_positions\\\n",
    "    .withColumn(\"timestamp\", col(\"req_time\") - col(\"seconds_since_report\"))\\\n",
    "    .select(col(\"id\").alias(\"bus_id\"), \"latitude\", \"longitude\", \"route_id\", substring(\"run_id\", -1, 1).alias(\"direction\"), \"timestamp\")\\\n",
    "\n",
    "# add day_type field, 0 if is weekday, 1 if is weekend or holiday\n",
    "bus_positions = bus_positions\\\n",
    "    .withColumn(\"day_type\", get_day_type(\"timestamp\"))\n",
    "\n",
    "# add timebin field (each timebin is 10 minutes, so there will be 144 timebins a day)\n",
    "bus_positions = bus_positions\\\n",
    "    .withColumn(\"time_bin\", get_time_bin(\"timestamp\"))\n",
    "\n",
    "# get segment id of bus positions\n",
    "bus_positions = bus_positions\\\n",
    "    .join(routes_segments, \"route_id\")\\\n",
    "    .withColumn(\"bus_segment_distance\", haversine_meter(\"latitude\", \"longitude\", \"segment_first_lat\", \"segment_first_lon\") + haversine_meter(\"latitude\", \"longitude\", \"segment_second_lat\", \"segment_second_lon\") - col(\"segment_len_meter\"))\\\n",
    "    .withColumn(\"row_number\", row_number().over(Window.partitionBy(\"bus_id\", \"route_id\", \"latitude\", \"longitude\", \"direction\").orderBy(asc(\"bus_segment_distance\"))))\\\n",
    "    .where(\"row_number = 1\")\\\n",
    "    .drop(\"row_number\")\\\n",
    "    .orderBy(\"bus_id\", \"route_id\", \"timestamp\")\n",
    "\n",
    "# drop rows with at least one null column\n",
    "bus_positions = bus_positions.dropna(\"any\")\n",
    "\n",
    "bus_positions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411ea864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get velocity of bus\n",
    "bus_velocities = bus_positions\n",
    "    .join(avg_velocities, \"route_id\", \"segment_id\", \"day_type\", \"time_bin\", \"direction\")\\\n",
    "    \n",
    "bus_velocities.show(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
