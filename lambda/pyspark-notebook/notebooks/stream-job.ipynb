{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c964e372",
   "metadata": {},
   "source": [
    "# Define static variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf0be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = \"hdfs://namenode:8020/spark/checkpoint\"\n",
    "\n",
    "DAY_TYPE_WEEKDAY = 0\n",
    "DAY_TYPE_WEEKEND = 1\n",
    "DATA_ACTUAL_TIMEZONE = \"America/Los_Angeles\"\n",
    "\n",
    "BOOTSTRAP_SERVER = \"kafka:29092\"\n",
    "TOPIC = \"buses-location\"\n",
    "\n",
    "POSTGRES_URL = \"jdbc:postgresql://timescaledb:5432/lametro\"\n",
    "POSTGRES_TABLE_BUS_VELOCITY = \"bus_velocity\"\n",
    "POSTGRES_TABLE_BUS_ARRIVAL = \"bus_arrival\"\n",
    "POSTGRES_USERNAME = \"postgres\"\n",
    "POSTGRES_PASSWORD = \"password\"\n",
    "\n",
    "STATIC_DATA_DIR = \"hdfs://namenode:8020/ola/static_data/\"\n",
    "HISTORICAL_DATA_DIR = \"hdfs://namenode:8020/ola/historical_data/\"\n",
    "AGGREGATED_DATA_DIR = \"hdfs://namenode:8020/ola/aggregated_data/\"\n",
    "TEMP_DIR = \"hdfs://namenode:8020/temp\"\n",
    "\n",
    "LOCAL_STATIC_DATA_DIR = \"/home/data/static_data/\"\n",
    "LOCAL_HISTORICAL_DATA_DIR = \"/home/data/historical_data/\"\n",
    "LOCAL_AGGREGATED_DATA_DIR = \"/home/data/aggregated_data/\"\n",
    "LOCAL_TEMP_DIR = \"/home/data/temp\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2b7690",
   "metadata": {},
   "source": [
    "# Init PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd68b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark import  SparkContext, SparkConf\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "# Spark session & context\n",
    "conf = SparkConf()\n",
    "conf.setMaster(\"spark://0.0.0.0:7077\").setAppName(\"stream-job\")\n",
    "conf.set(\"spark.cores.max\", \"4\")\n",
    "conf.set(\"spark.driver.extraClassPath\", \"/usr/local/spark/third-party-jars/*\")\n",
    "conf.set(\"spark.executor.extraClassPath\", \"/usr/local/spark/third-party-jars/*\")\n",
    "conf.set(\"spark.sql.caseSensitive\", \"true\")\n",
    "conf.set(\"spark.ui.port\", \"4040\")\n",
    "conf.set(\"spark.sql.streaming.checkpointLocation\", CHECKPOINT_DIR)\n",
    "conf.set(\"spark.streaming.backpressure.enabled\", \"true\")\n",
    "conf.set(\"spark.streaming.receiver.maxRate\", \"100\")\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "sqlContext = SQLContext(sc)\n",
    "ssc = StreamingContext(sc, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7f5fa63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.output_area pre {\n",
       "    white-space: pre;\n",
       "}\n",
       ".container { \n",
       "    width:95% !important; \n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "div.output_area pre {\n",
    "    white-space: pre;\n",
    "}\n",
    ".container { \n",
    "    width:95% !important; \n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d862f1",
   "metadata": {},
   "source": [
    "# Define utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06de0b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cd6794",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe7d4ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "\n",
    "# check if segment is not an empty segment (two vertex is the same)\n",
    "def fis_not_the_same(from_latlon, to_latlon):\n",
    "    return (from_latlon[0] != to_latlon[0]) | (from_latlon[1] != to_latlon[1])\n",
    "\n",
    "def ffile_path_to_ts(file_path):\n",
    "    return int(file_path[-18:-4])\n",
    "\n",
    "def fget_day_type(epoch_seconds):\n",
    "    dt = datetime.fromtimestamp(epoch_seconds)\n",
    "    wd = dt.astimezone(timezone(DATA_ACTUAL_TIMEZONE)).weekday()\n",
    "    return DAY_TYPE_WEEKDAY if wd < 5 else DAY_TYPE_WEEKEND\n",
    "\n",
    "def fhaversine_meter(lat1, lon1, lat2, lon2):\n",
    "    # distance between latitudes and longitudes\n",
    "    dLat = (lat2 - lat1) * math.pi / 180.0\n",
    "    dLon = (lon2 - lon1) * math.pi / 180.0\n",
    "\n",
    "    # convert to radians\n",
    "    lat1 = (lat1) * math.pi / 180.0\n",
    "    lat2 = (lat2) * math.pi / 180.0\n",
    " \n",
    "    # apply formulae\n",
    "    a = (math.pow(math.sin(dLat / 2), 2) +\n",
    "         math.pow(math.sin(dLon / 2), 2) *\n",
    "             math.cos(lat1) * math.cos(lat2));\n",
    "    rad = 6371\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    return rad * c * 1000\n",
    "\n",
    "def ffind_distance(lat1, lon1, flat1, flon1, slat1, slon1, cl1, lat2, lon2, flat2, flon2, slat2, slon2, cl2):\n",
    "    if cl1 == cl2:\n",
    "        return fhaversine_meter(lat1, lon1, lat2, lon2)\n",
    "        \n",
    "    if cl1 > cl2:\n",
    "        return ffind_distance(lat2, lon2, flat2, flon2, slat2, slon2, cl2, lat1, lon1, flat1, flon1, slat1, slon1, cl1)\n",
    "\n",
    "    return fhaversine_meter(lat1, lon1, slat1, slon1) + cl2 - cl1 - fhaversine_meter(flat2, flon2, slat2, slon2) + fhaversine_meter(flat2, flon2, lat2, lon2)\n",
    "\n",
    "def fto_datetime(epoch_seconds):\n",
    "    return datetime.fromtimestamp(epoch_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a8791d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffind_distance: 3913.794621512769 m\n"
     ]
    }
   ],
   "source": [
    "print(\"ffind_distance:\", ffind_distance(33.82962, -118.290314, 33.8292539188, -118.2902737058, 33.8296908268, -118.2902719251, 23232.5956910088, 33.794449, -118.290871, 33.7932864432, -118.2908173976, 33.7945806653, -118.2908159585, 19326.593863383834), \"m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a296a056",
   "metadata": {},
   "source": [
    "## Udf functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2aaff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#udf\n",
    "is_not_the_same = udf(lambda a, b: ffis_not_the_same(a, b), BooleanType())\n",
    "\n",
    "file_path_to_ts = udf(lambda a: ffile_path_to_ts(a), LongType())\n",
    "\n",
    "get_day_type = udf(lambda a: fget_day_type(a), IntegerType())\n",
    "\n",
    "haversine_meter = udf(lambda a, b, c, d: fhaversine_meter(a, b, c, d), DoubleType())\n",
    "\n",
    "find_distance = udf(lambda a, b, c, d, e, f, g, h, p, q, r, s, t, u: ffind_distance(a, b, c, d, e, f, g, h, p, q, r, s, t, u), DoubleType())\n",
    "\n",
    "alias_route_id = { 17:16, 48:10, 37:14, 38:35, 52:51, 79:78, 91:90, 240:150, 163:162, 181:180, 215:211, 245:244, 267:264, 243:242, 489:487, 656:237, 687:686, 950:910 }\n",
    "\n",
    "replace_alias_route_id = udf(\n",
    "    lambda rid: rid if rid not in alias_route_id else alias_route_id[rid],\n",
    "    IntegerType()\n",
    ")\n",
    "\n",
    "to_datetime = udf(lambda epoch_seconds: fto_datetime(epoch_seconds), TimestampType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a522d1",
   "metadata": {},
   "source": [
    "# Load static data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5435de6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- map: map (nullable = true)\n",
      " |    |-- key: integer\n",
      " |    |-- value: map (valueContainsNull = true)\n",
      " |    |    |-- key: integer\n",
      " |    |    |-- value: struct (valueContainsNull = true)\n",
      " |    |    |    |-- segment_id: integer (nullable = true)\n",
      " |    |    |    |-- segment_sequence: integer (nullable = true)\n",
      " |    |    |    |-- segment_first_lat: double (nullable = true)\n",
      " |    |    |    |-- segment_first_lon: double (nullable = true)\n",
      " |    |    |    |-- segment_second_lat: double (nullable = true)\n",
      " |    |    |    |-- segment_second_lon: double (nullable = true)\n",
      " |    |    |    |-- segment_len_meter: double (nullable = true)\n",
      " |    |    |    |-- segment_cum_len: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combine_maps = udf(\n",
    "    lambda maps: {key:f[key] for f in maps for key in f},\n",
    "    MapType(\n",
    "        IntegerType(),\n",
    "        StructType([\n",
    "            StructField(\"segment_id\", IntegerType(), True),\n",
    "            StructField(\"segment_sequence\", IntegerType(), True),\n",
    "            StructField(\"segment_first_lat\", DoubleType(), True),\n",
    "            StructField(\"segment_first_lon\", DoubleType(), True),\n",
    "            StructField(\"segment_second_lat\", DoubleType(), True),\n",
    "            StructField(\"segment_second_lon\", DoubleType(), True),\n",
    "            StructField(\"segment_len_meter\", DoubleType(), True),\n",
    "            StructField(\"segment_cum_len\", DoubleType(), True)\n",
    "        ])\n",
    "    )\n",
    ")\n",
    "\n",
    "combine_deep_maps = udf(\n",
    "    lambda maps: {key:f[key] for f in maps for key in f},\n",
    "    MapType(\n",
    "        IntegerType(),\n",
    "        MapType(\n",
    "            IntegerType(),\n",
    "            StructType([\n",
    "                StructField(\"segment_id\", IntegerType(), True),\n",
    "                StructField(\"segment_sequence\", IntegerType(), True),\n",
    "                StructField(\"segment_first_lat\", DoubleType(), True),\n",
    "                StructField(\"segment_first_lon\", DoubleType(), True),\n",
    "                StructField(\"segment_second_lat\", DoubleType(), True),\n",
    "                StructField(\"segment_second_lon\", DoubleType(), True),\n",
    "                StructField(\"segment_len_meter\", DoubleType(), True),\n",
    "                StructField(\"segment_cum_len\", DoubleType(), True)\n",
    "            ])\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "routes_segments = spark\\\n",
    "    .read\\\n",
    "    .json(STATIC_DATA_DIR + \"route_segments.json\")\\\n",
    "    .withColumn(\"route_id\", col(\"route_id\").cast(\"int\"))\\\n",
    "    .withColumn(\"segment_id\", col(\"segment_id\").cast(\"int\"))\\\n",
    "    .withColumn(\"segment_sequence\", col(\"segment_sequence\").cast(\"int\"))\\\n",
    "    .dropna()\\\n",
    "    .select(\n",
    "        replace_alias_route_id(\"route_id\").alias(\"route_id\"),\n",
    "        create_map(\"segment_sequence\", struct(\n",
    "            \"segment_id\", \"segment_sequence\", \"segment_first_lat\",\n",
    "            \"segment_first_lon\", \"segment_second_lat\", \"segment_second_lon\",\n",
    "            \"segment_len_meter\", \"segment_cum_len\"\n",
    "        )).alias(\"segment_info\")\n",
    "    )\\\n",
    "    .groupBy(\"route_id\")\\\n",
    "    .agg(combine_maps(collect_list(\"segment_info\")).alias(\"segments\"))\\\n",
    "    .agg(combine_deep_maps(collect_list(create_map(\"route_id\", \"segments\"))).alias(\"map\"))\\\n",
    "\n",
    "routes_segments.printSchema()\n",
    "\n",
    "broadcast_routes_segments = sc.broadcast(routes_segments.collect()[0][0])\n",
    "# broadcast_routes_segments.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "936b143b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- map: map (nullable = true)\n",
      " |    |-- key: integer\n",
      " |    |-- value: array (valueContainsNull = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- stop_id: integer (nullable = true)\n",
      " |    |    |    |-- stop_lat: double (nullable = true)\n",
      " |    |    |    |-- stop_lon: double (nullable = true)\n",
      " |    |    |    |-- stop_sequence: integer (nullable = true)\n",
      " |    |    |    |-- segment_sequence: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combine_maps = udf(\n",
    "    lambda maps: {key:f[key] for f in maps for key in f},\n",
    "    MapType(\n",
    "        IntegerType(),\n",
    "        ArrayType(\n",
    "            StructType([\n",
    "                StructField(\"stop_id\", IntegerType(), True),\n",
    "                StructField(\"stop_lat\", DoubleType(), True),\n",
    "                StructField(\"stop_lon\", DoubleType(), True),\n",
    "                StructField(\"stop_sequence\", IntegerType(), True),\n",
    "                StructField(\"segment_sequence\", IntegerType(), True)\n",
    "            ])\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "route_stops = spark\\\n",
    "    .read\\\n",
    "    .json(STATIC_DATA_DIR + \"route_stops.json\")\\\n",
    "    .withColumn(\"route_id\", col(\"route_id\").cast(\"int\"))\\\n",
    "    .withColumn(\"stop_id\", col(\"stop_id\").cast(\"int\"))\\\n",
    "    .dropna()\\\n",
    "    .select(\n",
    "        replace_alias_route_id(\"route_id\").alias(\"route_id\"),\n",
    "        struct(\n",
    "            \"stop_id\", \"stop_lat\", \"stop_lon\",\n",
    "            \"stop_sequence\", \"segment_sequence\"\n",
    "        ).alias(\"stop_info\")\n",
    "    )\\\n",
    "    .groupBy(\"route_id\")\\\n",
    "    .agg(collect_list(\"stop_info\").alias(\"stops\"))\\\n",
    "    .agg(combine_maps(collect_list(create_map(\"route_id\", \"stops\"))).alias(\"map\"))\\\n",
    "\n",
    "route_stops.printSchema()\n",
    "\n",
    "broadcast_route_stops = sc.broadcast(route_stops.collect()[0][0])\n",
    "# broadcast_route_stops.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0db4f45",
   "metadata": {},
   "source": [
    "# Load aggregated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bab067a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- map: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: struct (valueContainsNull = true)\n",
      " |    |    |-- velocity: double (nullable = true)\n",
      " |    |    |-- velocity_sign: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combine_maps = udf(\n",
    "    lambda maps: {key:f[key] for f in maps for key in f},\n",
    "    MapType(\n",
    "        StringType(),\n",
    "        StructType([\n",
    "            StructField(\"velocity\", DoubleType()),\n",
    "            StructField(\"velocity_sign\", IntegerType())\n",
    "        ])\n",
    "    )\n",
    ")\n",
    "\n",
    "bus_velocities = spark\\\n",
    "    .read\\\n",
    "    .json(AGGREGATED_DATA_DIR + \"bus_velocities.json\")\\\n",
    "    .withColumn(\"route_id\", replace_alias_route_id(\"route_id\"))\\\n",
    "    .select(combine_maps(collect_list(create_map(concat_ws(\"_\", \"route_id\", \"direction\", \"day_type\"), struct(\"velocity\", \"velocity_sign\")))).alias(\"map\"))\\\n",
    "\n",
    "bus_velocities.printSchema()\n",
    "\n",
    "broadcast_bus_velocities = sc.broadcast(bus_velocities.collect()[0][0])\n",
    "# broadcast_bus_velocities.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4e1f16",
   "metadata": {},
   "source": [
    "# Consume data from Kafka & process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70cc2931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- route_id: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- run_id: string (nullable = true)\n",
      " |-- predictable: boolean (nullable = true)\n",
      " |-- seconds_since_report: long (nullable = true)\n",
      " |-- heading: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"route_id\", StringType(), True),\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"run_id\", StringType(), True),\n",
    "    StructField(\"predictable\", BooleanType(), True),\n",
    "    StructField(\"seconds_since_report\", LongType(), True),\n",
    "    StructField(\"heading\", DoubleType(), True),\n",
    "    StructField(\"latitude\", DoubleType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# Subscribe to 1 topic defaults to the earliest and latest offsets\n",
    "bus_positions = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", BOOTSTRAP_SERVER) \\\n",
    "    .option(\"subscribe\", TOPIC) \\\n",
    "    .load()\\\n",
    "\n",
    "# Cast select bus position fields & timestamp\n",
    "bus_positions = bus_positions\\\n",
    "    .withColumn('value', col('value').cast(\"string\"))\\\n",
    "    .withColumn('json_value', from_json(\"value\", schema))\\\n",
    "    .select(col(\"timestamp\").cast(\"long\"), \"json_value.*\")\n",
    "\n",
    "bus_positions.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b9b553",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cab694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- bus_id: integer (nullable = true)\n",
      " |-- route_id: integer (nullable = true)\n",
      " |-- direction: integer (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- req_time: long (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- day_type: integer (nullable = true)\n",
      " |-- fixed_route_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform fields\n",
    "bus_positions_1 = bus_positions\\\n",
    "    .select(\n",
    "        col(\"id\").cast(\"int\").alias(\"bus_id\"), \n",
    "        col(\"route_id\").cast(\"int\"), \n",
    "        substring(\"run_id\", -1, 1).cast(\"int\").alias(\"direction\"),\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        col(\"timestamp\").alias(\"req_time\"),\n",
    "        (col(\"timestamp\") - col(\"seconds_since_report\")).alias(\"timestamp\")\n",
    "    )\\\n",
    "    .withColumn(\"day_type\", get_day_type(\"timestamp\"))\\\n",
    "    .dropna(\"any\")\\\n",
    "\n",
    "# Fix route id unconsistent\n",
    "bus_positions_1 = bus_positions_1\\\n",
    "    .withColumn(\"fixed_route_id\", replace_alias_route_id(\"route_id\"))\\\n",
    "\n",
    "bus_positions_1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "885c9c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fget_segment_info(route_id, lat, lon):\n",
    "    if route_id not in broadcast_routes_segments.value:\n",
    "        return None\n",
    "    \n",
    "    segment_dict = broadcast_routes_segments.value[route_id]\n",
    "    rs_segment_info = -1\n",
    "    rs_dis = math.inf\n",
    "    \n",
    "    for segment_info in segment_dict.values():\n",
    "        dis = fhaversine_meter(lat, lon, segment_info[\"segment_first_lat\"], segment_info[\"segment_first_lon\"]) \\\n",
    "            + fhaversine_meter(lat, lon, segment_info[\"segment_second_lat\"], segment_info[\"segment_second_lon\"]) \\\n",
    "            - segment_info[\"segment_len_meter\"]\n",
    "        \n",
    "        if dis < rs_dis:\n",
    "            rs_dis = dis\n",
    "            rs_segment_info = segment_info\n",
    "            \n",
    "    return rs_segment_info\n",
    "\n",
    "get_segment_info = udf(\n",
    "    lambda rid, lat, lon: fget_segment_info(rid, lat, lon), \n",
    "    StructType([\n",
    "        StructField(\"segment_id\", IntegerType(), True),\n",
    "        StructField(\"segment_sequence\", IntegerType(), True),\n",
    "        StructField(\"segment_first_lat\", DoubleType(), True),\n",
    "        StructField(\"segment_first_lon\", DoubleType(), True),\n",
    "        StructField(\"segment_second_lat\", DoubleType(), True),\n",
    "        StructField(\"segment_second_lon\", DoubleType(), True),\n",
    "        StructField(\"segment_len_meter\", DoubleType(), True),\n",
    "        StructField(\"segment_cum_len\", DoubleType(), True)\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a83ec560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(segment_id=49, segment_sequence=980002, segment_first_lat=34.1507053912, segment_first_lon=-118.1131582513, segment_second_lat=34.1517276036, segment_second_lon=-118.1131536861, segment_len_meter=113.66560913369601, segment_cum_len=30318.171651227352)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fget_segment_info(256, 34.151728, -118.113001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d90bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fget_velocity(route_id, direction, day_type):\n",
    "    key = f'{route_id}_{direction}_{day_type}'\n",
    "    if key in broadcast_bus_velocities.value:\n",
    "        return broadcast_bus_velocities.value[key]\n",
    "    else:\n",
    "        return next(iter(broadcast_bus_velocities.value.values()))\n",
    "\n",
    "get_velocity = udf(\n",
    "    lambda ri, dr, dt: fget_velocity(ri, dr, dt),\n",
    "    StructType([\n",
    "        StructField(\"velocity\", DoubleType()),\n",
    "        StructField(\"velocity_sign\", IntegerType())\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "548833a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(velocity=5.461573497132977, velocity_sign=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fget_velocity(256, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adf17c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fget_next_stops(route_id, bus_lat, bus_lon, velocity_sign, bus_segment_info):\n",
    "    stops = broadcast_route_stops.value[route_id]\n",
    "    bus_seg_seq = bus_segment_info[\"segment_sequence\"]\n",
    "    \n",
    "    result = []\n",
    "    for stop_info in stops:\n",
    "        if stop_info[\"segment_sequence\"] * velocity_sign >  bus_seg_seq * velocity_sign:\n",
    "            result.append(stop_info)\n",
    "            continue\n",
    "        \n",
    "        if stop_info[\"segment_sequence\"] == bus_seg_seq:\n",
    "            seg_flat = bus_segment_info[\"segment_first_lat\"]\n",
    "            seg_flon = bus_segment_info[\"segment_first_lon\"]\n",
    "            stp_lat = stop_info[\"stop_lat\"]\n",
    "            stp_lon = stop_info[\"stop_lon\"]\n",
    "            \n",
    "            if fhaversine_meter(stp_lat, stp_lon, seg_flat, seg_flon) * velocity_sign >= fhaversine_meter(bus_lat, bus_lon, seg_flat, seg_flon) * velocity_sign:\n",
    "                result.append(stop_info)\n",
    "    return result\n",
    "\n",
    "get_next_stops = udf(\n",
    "    lambda rid, blat, blon, vsign, bseginfo: fget_next_stops(rid, blat, blon, vsign, bseginfo),\n",
    "    ArrayType(StructType([\n",
    "        StructField(\"stop_id\", IntegerType(), True),\n",
    "        StructField(\"stop_lat\", DoubleType(), True),\n",
    "        StructField(\"stop_lon\", DoubleType(), True),\n",
    "        StructField(\"stop_sequence\", IntegerType(), True),\n",
    "        StructField(\"segment_sequence\", IntegerType(), True)\n",
    "    ]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3eda4eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(stop_id=10274, stop_lat=34.16914, stop_lon=-118.12481, stop_sequence=108, segment_sequence=1080001),\n",
       " Row(stop_id=10706, stop_lat=34.166921, stop_lon=-118.121392, stop_sequence=106, segment_sequence=1060001),\n",
       " Row(stop_id=2800, stop_lat=34.169146, stop_lon=-118.132093, stop_sequence=111, segment_sequence=1100003),\n",
       " Row(stop_id=10662, stop_lat=34.158095, stop_lon=-118.121346, stop_sequence=102, segment_sequence=1020001),\n",
       " Row(stop_id=3677, stop_lat=34.180119, stop_lon=-118.131598, stop_sequence=115, segment_sequence=1140003),\n",
       " Row(stop_id=10674, stop_lat=34.159867, stop_lon=-118.121345, stop_sequence=103, segment_sequence=1020003),\n",
       " Row(stop_id=10273, stop_lat=34.169091, stop_lon=-118.129944, stop_sequence=110, segment_sequence=1100001),\n",
       " Row(stop_id=3675, stop_lat=34.177308, stop_lon=-118.131719, stop_sequence=114, segment_sequence=1140001),\n",
       " Row(stop_id=3345, stop_lat=34.156215, stop_lon=-118.113014, stop_sequence=101, segment_sequence=1010001),\n",
       " Row(stop_id=10660, stop_lat=34.154124, stop_lon=-118.112994, stop_sequence=100, segment_sequence=990007),\n",
       " Row(stop_id=3676, stop_lat=34.173475, stop_lon=-118.131895, stop_sequence=113, segment_sequence=1120005),\n",
       " Row(stop_id=10276, stop_lat=34.169168, stop_lon=-118.121765, stop_sequence=107, segment_sequence=1070001),\n",
       " Row(stop_id=10644, stop_lat=34.151728, stop_lon=-118.113001, stop_sequence=99, segment_sequence=980002),\n",
       " Row(stop_id=2797, stop_lat=34.182216, stop_lon=-118.131499, stop_sequence=116, segment_sequence=1160001),\n",
       " Row(stop_id=3662, stop_lat=34.183645, stop_lon=-118.131438, stop_sequence=117, segment_sequence=1160001),\n",
       " Row(stop_id=10813, stop_lat=34.18587, stop_lon=-118.131878, stop_sequence=118, segment_sequence=1170003),\n",
       " Row(stop_id=10279, stop_lat=34.16911, stop_lon=-118.127547, stop_sequence=109, segment_sequence=1090001),\n",
       " Row(stop_id=3679, stop_lat=34.170801, stop_lon=-118.132016, stop_sequence=112, segment_sequence=1120001),\n",
       " Row(stop_id=10694, stop_lat=34.161917, stop_lon=-118.121365, stop_sequence=104, segment_sequence=1040001),\n",
       " Row(stop_id=10705, stop_lat=34.164725, stop_lon=-118.121379, stop_sequence=105, segment_sequence=1050001)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fget_next_stops(256, 34.151728, -118.113001, 1, fget_segment_info(256, 34.151728, -118.113001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76aea4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcalc_seconds_till_meet(route_id, bus_lat, bus_lon, bus_velocity, bus_segment_info, next_stop_info):\n",
    "    print(bus_segment_info)\n",
    "    \n",
    "    lat1 = bus_lat\n",
    "    lon1 = bus_lon\n",
    "    flat1 = bus_segment_info[\"segment_first_lat\"]\n",
    "    flon1 = bus_segment_info[\"segment_first_lon\"]\n",
    "    slat1 = bus_segment_info[\"segment_second_lat\"]\n",
    "    slon1 = bus_segment_info[\"segment_second_lon\"]\n",
    "    cl1 = bus_segment_info[\"segment_cum_len\"]\n",
    "    \n",
    "    stop_segment_info = broadcast_routes_segments.value[route_id][next_stop_info[\"segment_sequence\"]]\n",
    "    lat2 = next_stop_info[\"stop_lat\"]\n",
    "    lon2 = next_stop_info[\"stop_lon\"]\n",
    "    flat2 = stop_segment_info[\"segment_first_lat\"]\n",
    "    flon2 = stop_segment_info[\"segment_first_lon\"]\n",
    "    slat2 = stop_segment_info[\"segment_second_lat\"]\n",
    "    slon2 = stop_segment_info[\"segment_second_lon\"]\n",
    "    cl2 = stop_segment_info[\"segment_cum_len\"]\n",
    "    \n",
    "    dis = ffind_distance(lat1, lon1, flat1, flon1, slat1, slon1, cl1, lat2, lon2, flat2, flon2, slat2, slon2, cl2)\n",
    "    return math.floor(dis/bus_velocity)\n",
    "\n",
    "calc_seconds_till_meet = udf(\n",
    "    lambda rid, blat, blon, bvel, bseginfo, stpinfo: fcalc_seconds_till_meet(rid, blat, blon, bvel, bseginfo, stpinfo),\n",
    "    LongType()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72db604f",
   "metadata": {},
   "source": [
    "### Write historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "869b1a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data to HDFS for later batch processing\n",
    "historical_data_writer = bus_positions\\\n",
    "    .writeStream\\\n",
    "    .format(\"json\")\\\n",
    "    .option(\"path\", HISTORICAL_DATA_DIR)\\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27197c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_data_writer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db55c67",
   "metadata": {},
   "source": [
    "### Write to TimescaleDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "411ea864",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def processBatch(batch, batch_id):\n",
    "#     batch_df =  batch\\\n",
    "#         .withColumn(\"velocity\", get_velocity(\"fixed_route_id\", \"direction\", \"day_type\"))\\\n",
    "#         .withColumn(\"timestamp\", to_datetime(\"timestamp\"))\\\n",
    "#         .withColumn(\"req_time\", to_datetime(\"req_time\"))\\\n",
    "#         .withColumn(\"segment_info\", get_segment_info(\"fixed_route_id\", \"latitude\", \"longitude\"))\\\n",
    "#         .dropna(\"any\")\\\n",
    "#         .withColumn(\"next_stop_info\", explode(get_next_stops(\"fixed_route_id\", \"latitude\", \"longitude\", \"velocity.velocity_sign\", \"segment_info\")))\\\n",
    "#         .withColumn(\"seconds_till_meet\", calc_seconds_till_meet(\"fixed_route_id\", \"latitude\", \"longitude\", \"velocity.velocity\", \"segment_info\", \"next_stop_info\"))\\\n",
    "#         .select(\n",
    "#             \"timestamp\",\n",
    "#             \"req_time\",\n",
    "#             \"route_id\",\n",
    "#             \"bus_id\",\n",
    "#             \"latitude\",\n",
    "#             \"longitude\",\n",
    "#             \"direction\",\n",
    "#             col(\"velocity.velocity\").alias(\"velocity\"),\n",
    "#             col(\"next_stop_info.stop_id\").alias(\"stop_id\"),\n",
    "#             \"seconds_till_meet\"\n",
    "#         )\n",
    "    \n",
    "#     batch_df \\\n",
    "#         .write \\\n",
    "#         .format(\"jdbc\") \\\n",
    "#         .option(\"url\", POSTGRES_URL) \\\n",
    "#         .option(\"dbtable\", POSTGRES_TABLE_BUS_ARRIVAL) \\\n",
    "#         .option(\"user\", POSTGRES_USERNAME) \\\n",
    "#         .option(\"password\", POSTGRES_PASSWORD) \\\n",
    "#         .mode(\"append\") \\\n",
    "#         .save()\n",
    "    \n",
    "# aggregated_data_writer = bus_positions_1\\\n",
    "#     .writeStream\\\n",
    "#     .foreachBatch(processBatch)\\\n",
    "#     .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34d9a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeJDBC(batch, batch_id):\n",
    "    batch \\\n",
    "        .write \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", POSTGRES_URL) \\\n",
    "        .option(\"dbtable\", POSTGRES_TABLE_BUS_ARRIVAL) \\\n",
    "        .option(\"user\", POSTGRES_USERNAME) \\\n",
    "        .option(\"password\", POSTGRES_PASSWORD) \\\n",
    "        .mode(\"append\") \\\n",
    "        .save()\n",
    "\n",
    "\n",
    "aggregated_data_writer = bus_positions_1\\\n",
    "    .withColumn(\"velocity\", get_velocity(\"fixed_route_id\", \"direction\", \"day_type\"))\\\n",
    "    .withColumn(\"timestamp\", to_datetime(\"timestamp\"))\\\n",
    "    .withColumn(\"req_time\", to_datetime(\"req_time\"))\\\n",
    "    .withColumn(\"segment_info\", get_segment_info(\"fixed_route_id\", \"latitude\", \"longitude\"))\\\n",
    "    .dropna(\"any\")\\\n",
    "    .withColumn(\"next_stop_info\", explode(get_next_stops(\"fixed_route_id\", \"latitude\", \"longitude\", \"velocity.velocity_sign\", \"segment_info\")))\\\n",
    "    .withColumn(\"seconds_till_meet\", calc_seconds_till_meet(\"fixed_route_id\", \"latitude\", \"longitude\", \"velocity.velocity\", \"segment_info\", \"next_stop_info\"))\\\n",
    "    .select(\n",
    "        \"timestamp\",\n",
    "        \"req_time\",\n",
    "        \"route_id\",\n",
    "        \"bus_id\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"direction\",\n",
    "        col(\"velocity.velocity\").alias(\"velocity\"),\n",
    "        col(\"next_stop_info.stop_id\").alias(\"stop_id\"),\n",
    "        \"seconds_till_meet\"\n",
    "    )\\\n",
    "    .writeStream\\\n",
    "    .foreachBatch(writeJDBC)\\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56b685d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data_writer.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
